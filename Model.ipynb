{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProgettoIDSMatricolaS4699037.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Hzbi_cYn2gW"
      },
      "source": [
        "Progetto finale IDS Davide Cifarelli S4699037"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-mOljzdcIZL"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F #cross entropy loss\n",
        "import torchtext\n",
        "from torchtext.legacy.data import Field, BucketIterator, Iterator\n",
        "from torchtext.legacy import data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from tokenize import tokenize, untokenize   #python tokenizer\n",
        "import spacy\n",
        "import io\n",
        "import random\n",
        "import math\n",
        "import time  \n",
        "from tqdm import tqdm\n",
        "from google.colab import files  #dataset\n",
        "from google.colab import drive\n",
        "from nltk.translate.bleu_score import sentence_bleu        #bleuscore\n",
        "from nltk.translate.bleu_score import SmoothingFunction"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM8Du2v3ofkA",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c2175857-9d92-4ea6-94a3-23367acb35fb"
      },
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ddab1b58-02e6-4c3c-8180-8f0da6aec6b4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ddab1b58-02e6-4c3c-8180-8f0da6aec6b4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving dataset.txt to dataset.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4yUmO2-_tno",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d4fccf-68e4-404c-b7d6-b54dbad493f3"
      },
      "source": [
        "%set_env CUDA_LAUNCH_BLOCKING = 1 # disabilita lanci del kernel asincroni ed e utile per il debugging"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: CUDA_LAUNCH_BLOCKING=1 # disabilita lanci del kernel asincroni ed e utile per il debugging\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53k3gK5Yp44J"
      },
      "source": [
        "Nel nostro dataset le righe che contengono le domande iniziano sempre con '#'.\n",
        "Tutto cio' che e' compreso tra due domande e' una risposta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1HR4YOwXXln"
      },
      "source": [
        "f = open(\"dataset.txt\", \"r\")\n",
        "filelines = f.readlines()\n",
        "totQA = []                                       # lista contente coppie di domande/risposte del nostro dataset\n",
        "QuestionAndAnswer = None\n",
        "for line in filelines:\n",
        "  if line[0] == \"#\":                           # ogni linea contente # e' una linea contente una domanda\n",
        "    if QuestionAndAnswer:\n",
        "      QuestionAndAnswer['solution'] = ''.join(QuestionAndAnswer['solution'])    \n",
        "      totQA.append(QuestionAndAnswer)                           # aggiungo la coppia domanda risposta\n",
        "    QuestionAndAnswer = {\"question\": None, \"solution\": []}\n",
        "    QuestionAndAnswer['question'] = line[1:]                  # aggiungo la domanda alla lista\n",
        "  else:\n",
        "    QuestionAndAnswer[\"solution\"].append(line)                # aggiungo tutte le linee dove e' scritta la soluzione\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swBfwcDaXEh5"
      },
      "source": [
        "Creo una funzione che funzioni da tokenizer per la sintassi di python usando la libreria ufficiale di python. [Documentazione](https://docs.python.org/3/library/tokenize.html) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UsevXhPgh1R"
      },
      "source": [
        "def tokenize_code(code_str):  \n",
        "    code_tokens = list(tokenize(io.BytesIO(code_str.encode('utf-8')).readline))\n",
        "    tokenized_output = []    #lista contenente tutti i token della frase in input\n",
        "    for i in range(0, len(code_tokens)):\n",
        "        tokenized_output.append((code_tokens[i].type, code_tokens[i].string))\n",
        "    return tokenized_output                                      "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha4PJu8vrhZW"
      },
      "source": [
        "Test di prova con una risposta del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vflDHKJ7rfZ2"
      },
      "source": [
        "sample = tokenize_code(totQA[1]['solution'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V-sePckv1-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f5011ea-2a4f-4b04-9c58-d93fbbec5299"
      },
      "source": [
        "print(sample)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(57, 'utf-8'), (1, 'def'), (1, 'add_two_numbers'), (53, '('), (1, 'num1'), (53, ','), (1, 'num2'), (53, ')'), (53, ':'), (4, '\\n'), (5, '    '), (1, 'sum'), (53, '='), (1, 'num1'), (53, '+'), (1, 'num2'), (4, '\\n'), (1, 'return'), (1, 'sum'), (4, '\\n'), (56, '\\n'), (56, '\\n'), (6, ''), (0, '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ00a5cwwHtL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9f0eb6-7136-494c-fe3e-c427565d86ac"
      },
      "source": [
        "print(untokenize(sample).decode('utf-8'))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def add_two_numbers (num1 ,num2 ):\n",
            "    sum =num1 +num2 \n",
            "    return sum \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nsoc0eCpb8e"
      },
      "source": [
        "Siccome il dataset e' abbastanza piccolo cerco di aumentarlo. Durante la tokenizzazione del codice in python applico una maschera su certe variabili, in \n",
        "maniera randomica per evitare che il modello non si concentri sui nomi delle variabili, ma sulla sintassi. Allo stesso tempo creo una lista di keyword che non devono essere considerate come variabili e quindi non vanno modificate.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbIMyrYapfwS"
      },
      "source": [
        "def augment_tokenize_code(code_str, mask_factor=0.3):\n",
        "\n",
        "    var_masked = {} # Dizionario che memorizza le variabili mascherate\n",
        "\n",
        "    # alcune parole che non dovrebbero essere trattate come normali variabili e\n",
        "    # quindi devono non devono essere modificate mentre aumentiamo il nostro dataset\n",
        "\n",
        "    skip_words = ['range', 'enumerate', 'print', 'ord', 'int', 'float', 'zip'\n",
        "                 'char', 'list', 'dict', 'tuple', 'set', 'len', 'sum', 'min',\n",
        "                 'max','False', 'None', 'True', 'and', 'as', 'assert', 'async',\n",
        "                 'await', 'break','class', 'continue', 'def', 'del', 'elif',\n",
        "                 'else', 'except', 'finally', 'for','from', 'global', 'if',\n",
        "                 'import', 'in', 'is', 'lambda', 'nonlocal', 'not', 'or',\n",
        "                 'pass', 'raise', 'return', 'try', 'while', 'with', 'yield']\n",
        "    \n",
        "    \n",
        "\n",
        "    counter = 1 #var counter\n",
        "    code_tokens = list(tokenize(io.BytesIO(code_str.encode('utf-8')).readline)) # tokenizzo la string in input\n",
        "    tokenized_output = []  # questa sara la nuova lista di tokens con le variabili mascherate\n",
        "\n",
        "    i=0\n",
        "    while i in  range(0, len(code_tokens)):\n",
        "      if code_tokens[i].type == 1 and code_tokens[i].string not in skip_words:\n",
        "        \n",
        "        if i>0 and code_tokens[i-1].string in ['def', '.', 'import', 'raise', 'except', 'class']: # evito di mascherare le parole successive a queste\n",
        "          skip_words.append(code_tokens[i].string)                                                 # aggiungo alla lista di skip le parole         \n",
        "          tokenized_output.append((code_tokens[i].type, code_tokens[i].string))\n",
        "        elif code_tokens[i].string in var_masked:                                                   # se gia mascherata la variabile\n",
        "          tokenized_output.append((code_tokens[i].type, var_masked[code_tokens[i].string]))\n",
        "        elif random.uniform(0, 1) > 1-mask_factor:                                                  # maschero in maniera randomica le variabili\n",
        "          var_masked[code_tokens[i].string] = 'var_' + str(counter)                             # variabili mascherate var_1,var_2...\n",
        "          counter+=1\n",
        "          tokenized_output.append((code_tokens[i].type, var_masked[code_tokens[i].string]))       #aggiungo le var mascherate\n",
        "        else:\n",
        "          skip_words.append(code_tokens[i].string)                                                 # se no aggiungo la variabile alla lista degli skip\n",
        "          tokenized_output.append((code_tokens[i].type, code_tokens[i].string))\n",
        "      \n",
        "      else:\n",
        "        tokenized_output.append((code_tokens[i].type, code_tokens[i].string))\n",
        "\n",
        "      i+=1\n",
        "    \n",
        "    return tokenized_output"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldHsmMxvtMFx"
      },
      "source": [
        "Test di prova con una risposta del dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HJwaBJOhdxb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00fc508e-1997-4818-e1df-e352f876ac03"
      },
      "source": [
        "sample = augment_tokenize_code(totQA[1]['solution'])\n",
        "print(sample)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(57, 'utf-8'), (1, 'def'), (1, 'add_two_numbers'), (53, '('), (1, 'num1'), (53, ','), (1, 'num2'), (53, ')'), (53, ':'), (4, '\\n'), (5, '    '), (1, 'sum'), (53, '='), (1, 'num1'), (53, '+'), (1, 'num2'), (4, '\\n'), (1, 'return'), (1, 'sum'), (4, '\\n'), (56, '\\n'), (56, '\\n'), (6, ''), (0, '')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciLm6oezs3A2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eed29d9-ed82-4ebc-8e00-f88dccc5d137"
      },
      "source": [
        "print(untokenize(sample).decode('utf-8'))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "def add_two_numbers (num1 ,num2 ):\n",
            "    sum =num1 +num2 \n",
            "    return sum \n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhBx_KFVaJIK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "559fa2b0-4309-424e-feec-7d257139ca2c"
      },
      "source": [
        "codeQA_df = pd.DataFrame(totQA)   #creo il dataframe del dataset\n",
        "\n",
        "for i in range(0,codeQA_df.shape[0]):\n",
        "  codeQA_df['question'].iloc[i] = codeQA_df['question'].iloc[i].lstrip('0123456789.- ') #alcune domande avevano un numero all'inizio quindi lo rimuovo\n",
        "\n",
        "codeQA_df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>solution</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>write a python program to add two numbers \\n</td>\n",
              "      <td>num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>write a python function to add two user provid...</td>\n",
              "      <td>def add_two_numbers(num1, num2):\\n    sum = nu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>write a program to find and print the largest ...</td>\n",
              "      <td>\\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &gt;=...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>write a program to find and print the smallest...</td>\n",
              "      <td>num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 &lt;= n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Write a python function to merge two given lis...</td>\n",
              "      <td>def merge_lists(l1, l2):\\n    return l1 + l2\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            question                                           solution\n",
              "0       write a python program to add two numbers \\n  num1 = 1.5\\nnum2 = 6.3\\nsum = num1 + num2\\npri...\n",
              "1  write a python function to add two user provid...  def add_two_numbers(num1, num2):\\n    sum = nu...\n",
              "2  write a program to find and print the largest ...  \\nnum1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 >=...\n",
              "3  write a program to find and print the smallest...  num1 = 10\\nnum2 = 12\\nnum3 = 14\\nif (num1 <= n...\n",
              "4  Write a python function to merge two given lis...  def merge_lists(l1, l2):\\n    return l1 + l2\\n..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JP8GNF2tbDg"
      },
      "source": [
        "Divido il mio dataset:\n",
        "Training (85%), validazione(7.5%), testing (7.5%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdHbscZsSJu"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "#msk1,msk2 sono liste di var booleane o true o false che corrispondono a ogni elemento del \n",
        "#dataframe code questions and answers, in corrispondenza dei valori true la riga del dataframe sara'\n",
        "#aggiunta al nuovo dataframe (train o validazione o test)\n",
        "\n",
        "msk1 = np.random.rand(len(codeQA_df)) < 0.85 \n",
        "\n",
        "train_df = codeQA_df[msk1]\n",
        "val_and_test_df = codeQA_df[~msk1]\n",
        "\n",
        "msk2 = np.random.rand(len(val_and_test_df)) < 0.5\n",
        "\n",
        "val_df = val_and_test_df[msk2]\n",
        "test_df = val_and_test_df[~msk2]\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2_E0-lAoTwC"
      },
      "source": [
        "#Seeds per cuda\n",
        "\n",
        "SEED = 123\n",
        "random.seed(SEED)                           # utilizzo seed per avere un primo valore random in base al seed scelto (per avere behaviour deterministico durante il training)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLID_2ZtixKY"
      },
      "source": [
        "# Qui uso i Torchtext Fields per costruire il vocabolario per il problema di apprendimento da sequenza a sequenza.\n",
        "# Per capire l'inizio e la fine di una stringa si usano due token rispettivamente <sos> e <eos>\n",
        "\n",
        "Input = data.Field(tokenize = 'spacy', init_token='<sos>', eos_token='<eos>', lower=True)\n",
        "\n",
        "Output = data.Field(tokenize = augment_tokenize_code, init_token='<sos>', eos_token='<eos>', \n",
        "                    lower=False)\n",
        "\n",
        "fields = [('Input', Input),('Output', Output)]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mxsyNTBtogcD"
      },
      "source": [
        "Estendo il vocabolario di 100x\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP_yJeqjoLLV"
      },
      "source": [
        "train_ex = []\n",
        "val_ex = []\n",
        "\n",
        "train_expansion = 100\n",
        "for j in range(train_expansion):\n",
        "  for i in range(train_df.shape[0]):\n",
        "      try:\n",
        "          ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "          train_ex.append(ex)\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "for i in range(val_df.shape[0]):\n",
        "    try:\n",
        "        ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "        val_ex.append(ex)\n",
        "    except:\n",
        "        pass       \n",
        "\n",
        "train_data = data.Dataset(train_ex, fields)   \n",
        "valid_data =  data.Dataset(val_ex, fields)\n",
        "\n",
        "Input.build_vocab(train_data, min_freq = 0)    #costruisco il vocabolario\n",
        "Output.build_vocab(train_data, min_freq = 0)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yT2ugDQwBSw"
      },
      "source": [
        "Utilizzo cuda per sfruttare la GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKF16jVza_xo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26620294-34f3-4ee8-e605-cc2570f24070"
      },
      "source": [
        "USE_CUDA = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "device"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd-C0ntd8x1e"
      },
      "source": [
        "L'architettura transformer puo' essere suddivisa in 3 parti:\n",
        "1. Un codificatore che codifica una sequenza di input in un vettore\n",
        "2. Un meccanismo di attenzione che fa focalizzare sulla parte piu importante della frase. Usato sia nel codificatore che nel decodificatore.\n",
        "3. Un decodificatore che decodifica il vettore in output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQYN9WDA9Hh_"
      },
      "source": [
        "Converto i token della sequenza di parole in inglese in embedding('tok_embedding') di lunghezza 'hid_dim'. Bisogna taggare ogni token con il suo indice di posizione per preservare le informazioni sequenziali. Creo un tensore di indici ('pos') e lo converto in un embedding('pos_embedding') di lunghezza 'hid_dim'. Questo è combinato con i token embeddings della sequenza per creare il tensore di input src. Il tensore src viene passato attraverso una serie di Encoder Layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NE6JimgOCz-w"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hid_dim, n_layers, n_heads, pf_dim,dropout, device, max_length = 1000):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device #cpu o cuda\n",
        "\n",
        "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)      #eseguo l'embedding dei token\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)     #eseguo l'embedding della posizione del token nella frase\n",
        "        \n",
        "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, n_heads, pf_dim,dropout,device) for _ in range(n_layers)])\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)   #dropout alcuni nodi vengono ignorati per evitare overfitting\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device) #radice quadrata della dimensione del vettore\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "        \n",
        "        batch_size = src.shape[0]\n",
        "        src_len = src.shape[1]\n",
        "\n",
        "        position = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)        \n",
        "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(position))\n",
        "        #applico il dropout\n",
        "\n",
        "        for layer in self.layers:     #l'input tensor src viene passato attraverso i layer\n",
        "            src = layer(src, src_mask)\n",
        "            \n",
        "        return src"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1E12pQr9REU"
      },
      "source": [
        "Un EncoderLayer è l'elemento di base dell'encoder del transformer. Il tensore src insieme alla sua maschera src (src_mask) vengono inviati in un multi-head self-attention per aiutare il nostro modello a concentrarsi sugli aspetti piu importanti del tensore src. L'output dell'operazione di attenzione è combinato con il tensore src e normalizzato per evitare gradient vanishing/exploding  durante l'allenamento. Questo output combinato viene inviato ad un FeedForward Layer.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LheiXWVFDEg"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim,  dropout, device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)          \n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout,device)\n",
        "        self.feedforward = FeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, src, src_mask):\n",
        "                        \n",
        "        _src, _ = self.self_attention(src, src, src, src_mask)     #self attention       \n",
        "        src = self.self_attn_layer_norm(src + self.dropout(_src))  #dropout  e normalizzazione        \n",
        "        _src = self.feedforward(src)                               #feedforward        \n",
        "        src = self.ff_layer_norm(src + self.dropout(_src))         #dropout  e normalizzazione \n",
        "        \n",
        "        return src"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3MtR2yd-Iaz"
      },
      "source": [
        "L'attenzione è un meccanismo che consente a un modello di concentrarsi sulle parti piu rilevanti della sequenza di input in base al compito da svolgere.\n",
        "\n",
        "Quando più canali (heads) di attenzione vengono applicati in parallelo a una singola fonte, si parla di attenzione multi-head. Essa aumenta la capacità di apprendimento del modello e quindi porta a risultati migliori."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZmeHfGhGzkN"
      },
      "source": [
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, dropout,device):\n",
        "        super().__init__()\n",
        "        \n",
        "        assert hid_dim % n_heads == 0 #True? Se si proseguo, hid_dim lunghezza dei token embedded\n",
        "        #Utilizzando multihead dividiamo N batch di vettori embedded per N heads\n",
        "\n",
        "        self.hid_dim = hid_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = hid_dim // n_heads  #arrotondo\n",
        "        \n",
        "        #v,q,k copie esatte del src tensor\n",
        "        self.fc_q = nn.Linear(hid_dim, hid_dim)  #singolo layer feedforward\n",
        "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
        "        self.fc_v = nn.Linear(hid_dim, hid_dim)       \n",
        "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
        "        #radice quadrata della dimensione di K\n",
        "        \n",
        "    def forward(self, query, key, value, mask = None):\n",
        "        \n",
        "        batch_size = query.shape[0]\n",
        "                \n",
        "        Q = self.fc_q(query)\n",
        "        K = self.fc_k(key)\n",
        "        V = self.fc_v(value)\n",
        "                \n",
        "        #con view creo delle copie del tensore base Q,K,V\n",
        "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)  # con permute calcolo la matrice trasposta\n",
        "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
        "                \n",
        "        \n",
        "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
        "        # qui moltiplico Q per la trasposta di K e divido il tutto per la dimensione di K\n",
        "        \n",
        "        if mask is not None:\n",
        "            energy = energy.masked_fill(mask == 0, -1e10)    #se e' presente una maschera quando trovo 0 sostituisco con -inf\n",
        "        \n",
        "        attention = torch.softmax(energy, dim = -1)    #calcolo la softmax del prodotto ricavato precendentemente\n",
        "                \n",
        "        x = torch.matmul(self.dropout(attention), V)   #infine per ottenere l'attentione moltiplico per V\n",
        "        \n",
        "        x = x.permute(0, 2, 1, 3).contiguous()         #creo una copia del tensore\n",
        "        \n",
        "        x = x.view(batch_size, -1, self.hid_dim)       \n",
        "        \n",
        "        x = self.fc_o(x)\n",
        "        \n",
        "        return x, attention"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjEVmTzG9uZ4"
      },
      "source": [
        "Un FeedForward Layer prende l'input combinato e lo elabora ulteriormente utilizzando due layer completamente connessi e una funzione di attivazione Relu tra di loro. Questo in combinazione con l'src è l'output finale di un EncoderLayer. Questo processo si ripete per ogni blocco EncoderLayer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9w9xDUKL7LU"
      },
      "source": [
        "class FeedforwardLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, pf_dim, dropout):\n",
        "        super().__init__()\n",
        "\n",
        "        #2 operatori lineari e un dropout e una ReLU nel feedforward layer        \n",
        "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
        "        self.fc_2 = nn.Linear(pf_dim, hid_dim)        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.dropout(torch.relu(self.fc_1(x)))        #dropout+ReLU\n",
        "        x = self.fc_2(x)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaHaOGNm_Isc"
      },
      "source": [
        "L' architettura di un Decoder è molto simile a quella dell'encoder con le differenze significative derivanti dalla presenza di due input diversi, la sequenza target (trg) e il vettore uscente dall'encoder. Proprio come abbiamo avuto un blocco EncoderLayer per Encoder, avremo un DecoderLayer che accetta come input la combinazione della sequenza di token dell'output di codice(tok_embedding) e gli indici posizionali per questi token (pos_embedding). E come accennato in precedenza, l'output dell'encoder funge anche da input per DecoderLayer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWBMMF45MMNS"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hid_dim, n_layers, n_heads, pf_dim, dropout, device, max_length = 10000):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.device = device #cuda o cpu\n",
        "\n",
        "        #ora nel decoder la sequenza di input e' l'output ovvero il codice in python\n",
        "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
        "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
        "        \n",
        "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, n_heads, pf_dim, dropout,device) for _ in range(n_layers)])\n",
        "        \n",
        "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask): # qui funziona come per l'encoder\n",
        "                \n",
        "        batch_size = trg.shape[0]\n",
        "        trg_len = trg.shape[1]\n",
        "        \n",
        "        position = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
        "\n",
        "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(position))\n",
        "        \n",
        "        for layer in self.layers:\n",
        "            trg, attention = layer(trg, enc_src, trg_mask, src_mask) \n",
        "        \n",
        "        output = self.fc_out(trg)\n",
        "            \n",
        "        return output, attention"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcK1-4qZ_WBM"
      },
      "source": [
        " Ogni DecoderLayer prevede due operazioni di attenzione:\n",
        "1. Self-attention sul trg.\n",
        "2. Multi-head attention che utilizza trg come vettore query Q e le uscite dell'encoder come vettore chiave K e valore V.\n",
        "\n",
        "La presenza di un multihead attention aggiuntivo differenzia il DecoderLayer da un EncoderLayer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMEr1IFUMxco"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, hid_dim, n_heads, pf_dim, dropout,device):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
        "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout,device)\n",
        "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout,device)\n",
        "        self.feedforward = FeedforwardLayer(hid_dim, pf_dim, dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    def forward(self, trg, enc_src, trg_mask, src_mask):\n",
        "        \n",
        "        _trg, _ = self.self_attention(trg, trg, trg, trg_mask)                      #self attention operator\n",
        "        \n",
        "        trg = self.self_attn_layer_norm(trg + self.dropout(_trg))                   #dropout e normalizzazione layer\n",
        "            \n",
        "        _trg, attention = self.encoder_attention(trg, enc_src, enc_src, src_mask)   #attention dell'encoder-decoder\n",
        "        \n",
        "        trg = self.enc_attn_layer_norm(trg + self.dropout(_trg))                    #dropout e normalizzazione layer\n",
        "                    \n",
        "        _trg = self.feedforward(trg)                                                #feedforward\n",
        "        \n",
        "        trg = self.ff_layer_norm(trg + self.dropout(_trg))                          #attention dell'encoder-decoder\n",
        "        \n",
        "        #la differenzia sostanziale qui con l'encoder e' che vi e' un multihead attention operator che considera sia l'output\n",
        "        #dell'encoder sia l'output del self attention del decoder \n",
        "        \n",
        "        return trg, attention"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udpPhQ2UN8oQ"
      },
      "source": [
        "La classe principale che implementa un transformer:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dr3Mg8OGN6ul"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, encoder, decoder, src_pad_idx, trg_pad_idx,device):\n",
        "        super().__init__()        \n",
        "        self.device=device\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "        self.trg_pad_idx = trg_pad_idx\n",
        "                \n",
        "    def make_src_mask(self, src): # questa maschera nasconde gli input nulli tra i tokens della frase in inglese\n",
        "        \n",
        "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2) #lo stesso tensore con una nuova dimensione in posizione 1 e 2\n",
        "        return src_mask\n",
        "    \n",
        "    def make_trg_mask(self, trg): # questa maschera nasconde le parole successive dell'output per evitare che influenzino la scelta delle prossime parole in output\n",
        "        \n",
        "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]       \n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool() # tril resituisce il triangolo inferiore sinistro della matrice e mette a zero gli altri valori\n",
        "        trg_mask = trg_pad_mask & trg_sub_mask                                                 # ones restituisce una matrice di 1\n",
        "        \n",
        "        return trg_mask\n",
        "\n",
        "    def forward(self, src, trg):\n",
        "        src_mask = self.make_src_mask(src)\n",
        "        trg_mask = self.make_trg_mask(trg)        \n",
        "        enc_src = self.encoder(src, src_mask)                \n",
        "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask)      \n",
        "        \n",
        "        return output, attention"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4zsZjSSWOSHc"
      },
      "source": [
        "INPUT_DIM = len(Input.vocab)\n",
        "OUTPUT_DIM = len(Output.vocab)\n",
        "HID_DIM = 256\n",
        "ENC_LAYERS = 3\n",
        "DEC_LAYERS = 3\n",
        "ENC_HEADS = 16\n",
        "DEC_HEADS = 16\n",
        "ENC_PF_DIM = 512\n",
        "DEC_PF_DIM = 512\n",
        "ENC_DROPOUT = 0.1\n",
        "DEC_DROPOUT = 0.1\n",
        "\n",
        "enc = Encoder(INPUT_DIM, HID_DIM, ENC_LAYERS, ENC_HEADS, ENC_PF_DIM, ENC_DROPOUT, device)\n",
        "dec = Decoder(OUTPUT_DIM, HID_DIM, DEC_LAYERS, DEC_HEADS, DEC_PF_DIM, DEC_DROPOUT, device)\n",
        "\n",
        "SRC_PAD_IDX = Input.vocab.stoi[Input.pad_token]\n",
        "TRG_PAD_IDX = Output.vocab.stoi[Output.pad_token]\n",
        "\n",
        "model = Transformer(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)\n",
        "\n",
        "def initialize_weights(m):\n",
        "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
        "        nn.init.xavier_uniform_(m.weight.data) #inizializzo i weights\n",
        "\n",
        "\n",
        "model.apply(initialize_weights);\n",
        "LEARNING_RATE = 0.0004  # learning rate ottimale per i problemi di NLP tra 3e-4 e 5e-4\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs2XdrveCtDD"
      },
      "source": [
        "Ho utilizzato la data augmentation per mascherare le variabili. Ciò significa che il modello può prevedere diversi valori per una variabile e tutti sono corretti se le previsioni sono coerenti. Ciò significa che le variabili usate nel training non sono per forza le uniche giuste e quindi ha più senso trattarle come corrette con probabilità 1- smooth_eps e errate altrimenti. Per questo utilizzo l'implementazione del CrossEntropyLoss con label smoothing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNfxmsLxD7yb"
      },
      "source": [
        "#codice sorgente cross entropy loss e label smoothing presentato nel paper Rethinking the Inception Architecture for Computer Vision: https://arxiv.org/abs/1512.00567 \n",
        "'''https://github.com/eladhoffer/utils.pytorch/blob/master/cross_entropy.py'''\n",
        "\n",
        "class CrossEntropyLoss(nn.CrossEntropyLoss):\n",
        "    def __init__(self, weight=None, ignore_index=-100, reduction='mean', smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "        super(CrossEntropyLoss, self).__init__(weight=weight,ignore_index=ignore_index, reduction=reduction)\n",
        "        self.smooth_eps = smooth_eps\n",
        "        self.smooth_dist = smooth_dist\n",
        "        self.from_logits = from_logits\n",
        "\n",
        "    def forward(self, input, target, smooth_dist=None):\n",
        "        if smooth_dist is None:\n",
        "            smooth_dist = self.smooth_dist\n",
        "        return cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index,\n",
        "                             reduction=self.reduction, smooth_eps=self.smooth_eps,\n",
        "                             smooth_dist=smooth_dist, from_logits=self.from_logits)\n",
        "\n",
        "\n",
        "def cross_entropy(inputs, target, weight=None, ignore_index=-100, reduction='mean',\n",
        "                  smooth_eps=None, smooth_dist=None, from_logits=True):\n",
        "    smooth_eps = smooth_eps or 0\n",
        "\n",
        "    #log-liklihood\n",
        "    if _is_long(target) and smooth_eps == 0:\n",
        "        if from_logits:\n",
        "            return F.cross_entropy(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)  \n",
        "        else:\n",
        "            return F.nll_loss(inputs, target, weight, ignore_index=ignore_index, reduction=reduction)   # perdita negativa log-likelihood\n",
        "\n",
        "    if from_logits:\n",
        "        lsm = F.log_softmax(inputs, dim=-1)\n",
        "    else:\n",
        "        lsm = inputs\n",
        "\n",
        "    masked_indices = None\n",
        "    num_classes = inputs.size(-1) \n",
        "\n",
        "    if _is_long(target) and ignore_index >= 0:\n",
        "        masked_indices = target.eq(ignore_index)\n",
        "\n",
        "    if smooth_eps > 0 and smooth_dist is not None:\n",
        "        if _is_long(target):\n",
        "            target = onehot(target, num_classes).type_as(inputs)\n",
        "        if smooth_dist.dim() < target.dim():\n",
        "            smooth_dist = smooth_dist.unsqueeze(0)\n",
        "        target.lerp_(smooth_dist, smooth_eps)\n",
        "\n",
        "    if weight is not None:\n",
        "        lsm = lsm * weight.unsqueeze(0)\n",
        "\n",
        "    if _is_long(target):\n",
        "        eps_sum = smooth_eps / num_classes\n",
        "        eps_nll = 1. - eps_sum - smooth_eps\n",
        "        likelihood = lsm.gather(dim=-1, index=target.unsqueeze(-1)).squeeze(-1)\n",
        "        loss = -(eps_nll * likelihood + eps_sum * lsm.sum(-1))\n",
        "    else:\n",
        "        loss = -(target * lsm).sum(-1)\n",
        "\n",
        "    if masked_indices is not None:\n",
        "        loss.masked_fill_(masked_indices, 0)\n",
        "\n",
        "    if reduction == 'sum':\n",
        "        loss = loss.sum()\n",
        "    elif reduction == 'mean':\n",
        "        if masked_indices is None:\n",
        "            loss = loss.mean()\n",
        "        else:\n",
        "            loss = loss.sum() / float(loss.size(0) - masked_indices.sum())\n",
        "\n",
        "    return loss\n",
        "\n",
        "#fine codice sorgente cross entropy + label smoothing\n",
        "\n",
        "def onehot(indexes, N=None, ignore_index=None):\n",
        "    #Crea una rappresentazione di indici con N possibili voci se N non è specificato, si adatterà all'indice massimo che appare.\n",
        "    #indexes e' un tensore long di indici\n",
        "    if N is None:\n",
        "        N = indexes.max() + 1\n",
        "    sz = list(indexes.size())\n",
        "    output = indexes.new().byte().resize_(*sz, N).zero_()\n",
        "    output.scatter_(-1, indexes.unsqueeze(-1), 1)\n",
        "    if ignore_index is not None and ignore_index >= 0:\n",
        "        output.masked_fill_(indexes.eq(ignore_index).unsqueeze(-1), 0)\n",
        "    return output\n",
        "\n",
        "def _is_long(x): #il tensore e' long? (64-bit int)\n",
        "    if hasattr(x, 'data'):\n",
        "        x = x.data\n",
        "    return isinstance(x, torch.LongTensor) or isinstance(x, torch.cuda.LongTensor)\n",
        "\n",
        "#mask loss\n",
        "def maskNLLLoss(inp, target, mask): # calcolo la perdita basandosi sul tensore output del decoder, il tensore target e un tensore binario per la maschera\n",
        "    nTotal = mask.sum()\n",
        "    crossEntropy = CrossEntropyLoss(ignore_index = TRG_PAD_IDX, smooth_eps=0.20)\n",
        "    loss = crossEntropy(inp, target)\n",
        "    loss = loss.to(device)\n",
        "    return loss, nTotal.item()\n",
        "\n",
        "criterion = maskNLLLoss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycBBiEpuO6cG"
      },
      "source": [
        "def make_trg_mask(trg): # funziona come quella definita prima nella classe Transformer\n",
        "      \n",
        "        trg_pad_mask = (trg != TRG_PAD_IDX).unsqueeze(1).unsqueeze(2)\n",
        "        trg_len = trg.shape[1]\n",
        "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()   \n",
        "        trg_mask = trg_pad_mask & trg_sub_mask        \n",
        "        return trg_mask\n",
        "\n",
        "#allenamento del modello\n",
        "def train(model, iterator, optimizer, criterion, clip):\n",
        "    \n",
        "    model.train() # dico al modello se siamo in modalita' allenamento o validazione, a seconda di questo la dropout si comporta diversamente\n",
        "    \n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)): #tqdm esegue il display della barra di progressione mentre alleniamo il modello\n",
        "        loss = 0\n",
        "        src = batch.Input.permute(1, 0) \n",
        "        trg = batch.Output.permute(1, 0)\n",
        "        trg_mask = make_trg_mask(trg)\n",
        "        optimizer.zero_grad()   #resetto la loss senza considerare quelle degli step precedenti\n",
        "        \n",
        "        output, _ = model(src, trg[:,:-1])                \n",
        "            \n",
        "        output_dim = output.shape[-1]\n",
        "            \n",
        "        output = output.contiguous().view(-1, output_dim)\n",
        "        trg = trg[:,1:].contiguous().view(-1)\n",
        "                           \n",
        "        mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "        \n",
        "        mask_loss.backward()   #calcola il loss gradient\n",
        "        \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)  #per evitare gradient exploding (forza i gradient ad essere abbastanza piccoli)\n",
        "        \n",
        "        optimizer.step()       #aggiorna tutti i parametri basandosi sul gradient\n",
        "        \n",
        "        print_losses.append(mask_loss.item() * nTotal)\n",
        "        n_totals += nTotal\n",
        "\n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi3Ev8gaO79_"
      },
      "source": [
        "#validazione del modello\n",
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()  # dico al modello se siamo in modalita' allenamento o validazione, a seconda di questo la dropout si comporta diversamente\n",
        "    \n",
        "    n_totals = 0\n",
        "    print_losses = []\n",
        "    \n",
        "    with torch.no_grad():  # salto il calcolo del gradiente, ovvero non cambio i weights\n",
        "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\n",
        "\n",
        "            src = batch.Input.permute(1, 0)\n",
        "            trg = batch.Output.permute(1, 0)\n",
        "            trg_mask = make_trg_mask(trg)\n",
        "\n",
        "            output, _ = model(src, trg[:,:-1])           \n",
        "            \n",
        "            output_dim = output.shape[-1]\n",
        "            \n",
        "            output = output.contiguous().view(-1, output_dim)\n",
        "            trg = trg[:,1:].contiguous().view(-1)            \n",
        "            \n",
        "            mask_loss, nTotal = criterion(output, trg, trg_mask)\n",
        "\n",
        "            print_losses.append(mask_loss.item() * nTotal)\n",
        "            n_totals += nTotal\n",
        "  \n",
        "    return sum(print_losses) / n_totals"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuB4JqQRO9Wg"
      },
      "source": [
        "def epoch_time(start_time, end_time): # calcolo il tempo che ci vuole per ogni epoch\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAhqAewGozhP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56b48a7-07c2-4721-eb90-be705ef44127"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPqDB7NIo2rm"
      },
      "source": [
        "model_save_name = 'engtopy.pt'  #salvo il modello sul mio drive\n",
        "path = F\"/content/gdrive/My Drive/{model_save_name}\""
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aax76Ie4O_Cr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98b5083-0da0-4b1a-943f-e154601aec47"
      },
      "source": [
        "N_EPOCHS = 60\n",
        "CLIP = 1\n",
        "\n",
        "best_valid_loss = float('inf')  #setto a +infinito\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_ex = []\n",
        "    val_ex = []\n",
        "\n",
        "    for i in range(train_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([train_df.question[i], train_df.solution[i]], fields)\n",
        "            train_ex.append(ex)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    for i in range(val_df.shape[0]):\n",
        "        try:\n",
        "            ex = data.Example.fromlist([val_df.question[i], val_df.solution[i]], fields)\n",
        "            val_ex.append(ex)\n",
        "        except:\n",
        "            pass       \n",
        "\n",
        "    train_data = data.Dataset(train_ex, fields)\n",
        "    valid_data =  data.Dataset(val_ex, fields)\n",
        "\n",
        "    BATCH_SIZE = 16\n",
        "    #creazione dei batches in maniera ottimale ovvero con esempi simili in ogni batch tramite Pytorchtext \n",
        "    #grazie a x: len(x.Input) avro' in ogni batch degli input di lunghezza simile\n",
        "    train_iterator, valid_iterator = BucketIterator.splits((train_data, valid_data), batch_size = BATCH_SIZE, \n",
        "                                                                sort_key = lambda x: len(x.Input),\n",
        "                                                                sort_within_batch=True, device = device)\n",
        "\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP) #allenamento \n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)               #validazione \n",
        "    \n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:   # se migliora la perdita (diminuisce) nella validazione allora salvo come migliore \n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), path)\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.35it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 59.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 1m 25s\n",
            "\tTrain Loss: 4.988\n",
            "\t Val. Loss: 4.206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.58it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 59.95it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Time: 1m 23s\n",
            "\tTrain Loss: 4.222\n",
            "\t Val. Loss: 3.920\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.45it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.09it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Time: 1m 23s\n",
            "\tTrain Loss: 3.995\n",
            "\t Val. Loss: 3.791\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.14it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Time: 1m 24s\n",
            "\tTrain Loss: 3.850\n",
            "\t Val. Loss: 3.721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 11.05it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.16it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Time: 1m 26s\n",
            "\tTrain Loss: 3.723\n",
            "\t Val. Loss: 3.590\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 11.07it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Time: 1m 25s\n",
            "\tTrain Loss: 3.621\n",
            "\t Val. Loss: 3.529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.33it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Time: 1m 24s\n",
            "\tTrain Loss: 3.532\n",
            "\t Val. Loss: 3.439\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.15it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.24it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Time: 1m 24s\n",
            "\tTrain Loss: 3.454\n",
            "\t Val. Loss: 3.410\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.25it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 65.78it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Time: 1m 24s\n",
            "\tTrain Loss: 3.376\n",
            "\t Val. Loss: 3.383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.21it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.75it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Time: 1m 24s\n",
            "\tTrain Loss: 3.309\n",
            "\t Val. Loss: 3.300\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.20it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 62.46it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 | Time: 1m 23s\n",
            "\tTrain Loss: 3.249\n",
            "\t Val. Loss: 3.305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.18it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 59.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 | Time: 1m 23s\n",
            "\tTrain Loss: 3.193\n",
            "\t Val. Loss: 3.249\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.24it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 | Time: 1m 23s\n",
            "\tTrain Loss: 3.152\n",
            "\t Val. Loss: 3.227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 11.10it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 65.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 | Time: 1m 23s\n",
            "\tTrain Loss: 3.100\n",
            "\t Val. Loss: 3.170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.24it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 59.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 | Time: 1m 23s\n",
            "\tTrain Loss: 3.072\n",
            "\t Val. Loss: 3.153\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.30it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 68.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16 | Time: 1m 23s\n",
            "\tTrain Loss: 3.030\n",
            "\t Val. Loss: 3.129\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.11it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 68.06it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17 | Time: 1m 24s\n",
            "\tTrain Loss: 2.992\n",
            "\t Val. Loss: 3.109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 11.05it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 67.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18 | Time: 1m 24s\n",
            "\tTrain Loss: 2.960\n",
            "\t Val. Loss: 3.093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.24it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.25it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19 | Time: 1m 23s\n",
            "\tTrain Loss: 2.931\n",
            "\t Val. Loss: 3.081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 11.03it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.99it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20 | Time: 1m 24s\n",
            "\tTrain Loss: 2.915\n",
            "\t Val. Loss: 3.090\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.23it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 67.94it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 21 | Time: 1m 23s\n",
            "\tTrain Loss: 2.892\n",
            "\t Val. Loss: 3.066\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.18it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.77it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 22 | Time: 1m 24s\n",
            "\tTrain Loss: 2.874\n",
            "\t Val. Loss: 3.112\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.22it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.96it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 23 | Time: 1m 24s\n",
            "\tTrain Loss: 2.849\n",
            "\t Val. Loss: 3.058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.21it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 57.93it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 24 | Time: 1m 23s\n",
            "\tTrain Loss: 2.832\n",
            "\t Val. Loss: 3.018\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.26it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 61.87it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 25 | Time: 1m 24s\n",
            "\tTrain Loss: 2.818\n",
            "\t Val. Loss: 3.024\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.16it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 61.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 26 | Time: 1m 24s\n",
            "\tTrain Loss: 2.802\n",
            "\t Val. Loss: 3.020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.28it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.27it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 27 | Time: 1m 24s\n",
            "\tTrain Loss: 2.795\n",
            "\t Val. Loss: 2.980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.28it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 58.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 28 | Time: 1m 23s\n",
            "\tTrain Loss: 2.781\n",
            "\t Val. Loss: 2.998\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.17it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 58.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 29 | Time: 1m 24s\n",
            "\tTrain Loss: 2.762\n",
            "\t Val. Loss: 2.972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.15it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 30 | Time: 1m 24s\n",
            "\tTrain Loss: 2.751\n",
            "\t Val. Loss: 3.014\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.34it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.47it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 31 | Time: 1m 23s\n",
            "\tTrain Loss: 2.743\n",
            "\t Val. Loss: 3.031\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.25it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.45it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 32 | Time: 1m 23s\n",
            "\tTrain Loss: 2.726\n",
            "\t Val. Loss: 3.005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.21it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.48it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 33 | Time: 1m 24s\n",
            "\tTrain Loss: 2.717\n",
            "\t Val. Loss: 2.987\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.28it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.37it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 34 | Time: 1m 24s\n",
            "\tTrain Loss: 2.705\n",
            "\t Val. Loss: 2.948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:20<00:00, 10.96it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 65.68it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 35 | Time: 1m 25s\n",
            "\tTrain Loss: 2.698\n",
            "\t Val. Loss: 2.961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.14it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 36 | Time: 1m 24s\n",
            "\tTrain Loss: 2.692\n",
            "\t Val. Loss: 2.965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.25it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.34it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 37 | Time: 1m 23s\n",
            "\tTrain Loss: 2.683\n",
            "\t Val. Loss: 3.005\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.31it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.91it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 38 | Time: 1m 23s\n",
            "\tTrain Loss: 2.678\n",
            "\t Val. Loss: 2.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.27it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.23it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 39 | Time: 1m 23s\n",
            "\tTrain Loss: 2.667\n",
            "\t Val. Loss: 2.964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.23it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 65.44it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 40 | Time: 1m 23s\n",
            "\tTrain Loss: 2.655\n",
            "\t Val. Loss: 2.954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.21it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 41 | Time: 1m 23s\n",
            "\tTrain Loss: 2.655\n",
            "\t Val. Loss: 3.008\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.21it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.92it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 42 | Time: 1m 23s\n",
            "\tTrain Loss: 2.652\n",
            "\t Val. Loss: 2.982\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.30it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 60.08it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 43 | Time: 1m 23s\n",
            "\tTrain Loss: 2.645\n",
            "\t Val. Loss: 2.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.18it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 65.86it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 44 | Time: 1m 24s\n",
            "\tTrain Loss: 2.635\n",
            "\t Val. Loss: 2.917\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.19it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.01it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 45 | Time: 1m 24s\n",
            "\tTrain Loss: 2.630\n",
            "\t Val. Loss: 2.949\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.14it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.60it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 46 | Time: 1m 23s\n",
            "\tTrain Loss: 2.621\n",
            "\t Val. Loss: 2.951\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.17it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.29it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 47 | Time: 1m 23s\n",
            "\tTrain Loss: 2.617\n",
            "\t Val. Loss: 2.910\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.29it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 48 | Time: 1m 23s\n",
            "\tTrain Loss: 2.613\n",
            "\t Val. Loss: 2.978\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.23it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 61.59it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 49 | Time: 1m 23s\n",
            "\tTrain Loss: 2.610\n",
            "\t Val. Loss: 2.957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.23it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.10it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 50 | Time: 1m 24s\n",
            "\tTrain Loss: 2.602\n",
            "\t Val. Loss: 2.932\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.19it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 58.97it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 51 | Time: 1m 24s\n",
            "\tTrain Loss: 2.597\n",
            "\t Val. Loss: 2.965\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.28it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 69.56it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 52 | Time: 1m 24s\n",
            "\tTrain Loss: 2.596\n",
            "\t Val. Loss: 2.936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.26it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.03it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 53 | Time: 1m 24s\n",
            "\tTrain Loss: 2.588\n",
            "\t Val. Loss: 2.956\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.32it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 63.50it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 54 | Time: 1m 23s\n",
            "\tTrain Loss: 2.585\n",
            "\t Val. Loss: 2.960\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.30it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 60.88it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 55 | Time: 1m 23s\n",
            "\tTrain Loss: 2.581\n",
            "\t Val. Loss: 2.974\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.13it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 64.26it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 56 | Time: 1m 23s\n",
            "\tTrain Loss: 2.577\n",
            "\t Val. Loss: 2.980\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.15it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 66.13it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 57 | Time: 1m 23s\n",
            "\tTrain Loss: 2.576\n",
            "\t Val. Loss: 2.940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.11it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 61.30it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 58 | Time: 1m 24s\n",
            "\tTrain Loss: 2.569\n",
            "\t Val. Loss: 2.944\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.18it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 62.98it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 59 | Time: 1m 24s\n",
            "\tTrain Loss: 2.570\n",
            "\t Val. Loss: 2.936\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 222/222 [00:19<00:00, 11.17it/s]\n",
            "100%|██████████| 3/3 [00:00<00:00, 67.47it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 60 | Time: 1m 24s\n",
            "\tTrain Loss: 2.563\n",
            "\t Val. Loss: 2.954\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMKkB13yPeJ7"
      },
      "source": [
        "SRC = Input\n",
        "TRG = Output"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3_aq7QTPBFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89155c7-793c-4d9e-87ed-daa80bd43037"
      },
      "source": [
        "model.load_state_dict(torch.load(path))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieIjql9uPKH1"
      },
      "source": [
        "#funzione per testare il funzionamento del modello\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len = 50000):    \n",
        "    model.eval()\n",
        "        \n",
        "    if isinstance(sentence, str):\n",
        "        nlp = spacy.load('en')\n",
        "        tokens = [token.text.lower() for token in nlp(sentence)] #tokenizzazione\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]  #init e eos sono i tokens che segnalano l'inizio e la fine della frase\n",
        "        \n",
        "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]   #.stoi per mappare i src tokens con indici numerabili\n",
        "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)    \n",
        "    src_mask = model.make_src_mask(src_tensor)\n",
        "    \n",
        "    with torch.no_grad():                                            # salto il calcolo del gradiente, ovvero non cambio i weights\n",
        "        enc_src = model.encoder(src_tensor, src_mask)                # faccio passare l'src nell encoder\n",
        "\n",
        "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]       #.stoi per mappare i trg tokens con indici numerabili\n",
        "\n",
        "    for i in range(max_len):\n",
        "\n",
        "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
        "        trg_mask = model.make_trg_mask(trg_tensor)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask)   # faccio passare trg e src codificato dentro il decoder\n",
        "        \n",
        "        pred_token = output.argmax(2)[:,-1].item()                  #seleziona l'indice con il valore massimo\n",
        "        trg_indexes.append(pred_token)\n",
        "\n",
        "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
        "            break\n",
        "    \n",
        "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]    \n",
        "    \n",
        "    return trg_tokens[1:], attention"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lwaEkWxK8DA"
      },
      "source": [
        "Carico il modello preaddestrato per eseguire dei test su una serie di esempi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiYFFxnzj6Mn"
      },
      "source": [
        "model.load_state_dict(torch.load(path))\n",
        "\n",
        "def eng_to_python(src):\n",
        "  src=src.split(\" \")\n",
        "  translation, attention = translate_sentence(src, SRC, TRG, model, device)\n",
        "  #print(f'Soluzione: \\n') \n",
        "  #print(untokenize(translation[:-1]).decode('utf-8'))          #per i test\n",
        "\n",
        "  return untokenize(translation[:-1]).decode('utf-8')\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG3TsKgQWy4p"
      },
      "source": [
        "SRC = Input\n",
        "TRG = Output"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmEaL7CHsbUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "653fd9e0-c3d6-41f2-dab1-4d85c1017345"
      },
      "source": [
        "#bleu score\n",
        "nTest = test_df.shape[0]\n",
        "\n",
        "totalBleu = 0\n",
        "skipped = 0\n",
        "\n",
        "smoothie = SmoothingFunction().method4\n",
        "\n",
        "for i in range(0,nTest):         #testo il modello sul dataframe di test \n",
        "  try:\n",
        "    referenceTest = test_df['solution'].iloc[i].split()\n",
        "    candidateTest = (eng_to_python(test_df['question'].iloc[i])).split()\n",
        "    totalBleu += sentence_bleu(referenceTest,candidateTest,smoothing_function=smoothie)   \n",
        "    #calcolo il bleuScore totale di tutte le domande di test, provandole una alla volta\n",
        "  except:\n",
        "    skipped += 1\n",
        "    pass\n",
        "\n",
        "score = totalBleu/(nTest-skipped)\n",
        "\n",
        "print('BLEU score -> {}'.format(score))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score -> 0.16121748796741578\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSLAS7DDUzKQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fd8f52c1-0fc6-473a-ac1c-1f7b166b049d"
      },
      "source": [
        "src = \"function that subtract two numbers\"\n",
        "\n",
        "eng_to_python(src)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def sub_two_numbers (num1 ,num2 ):\\n    sub =num1 -num2 \\n    return sub '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaiTElExWDjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aebaadf0-bdf2-4fec-fe55-39c9a486b984"
      },
      "source": [
        "src = \"program to reverse a string\"\n",
        "\n",
        "eng_to_python(src)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nstring ='Today is bad day'\\nstring [::-1 ]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UjfV6aQWeCn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2eb6d835-1f1d-425a-98e0-876c2fdd727b"
      },
      "source": [
        "src = \"function to find the perimeter of a square\"\n",
        "\n",
        "eng_to_python(src)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'def square_perimeter (a ):\\n    return 4 *a '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}